---
title: "Análise de Contagens com o Modelo COM-Poisson"
author: >
  Walmes M. Zeviani,
  Eduardo E. Ribeiro Jr &
  Cesar A. Taconeli
vignette: >
  %\VignetteIndexEntry{Análise de Contagens com o Modelo COM-Poisson}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
source("_setup.R")
```

```{r}

library(MRDCr)

```

# Funções para ajuste dos modelos #

## Log-verossimilhança ##

Implentando a função de log-verossimilhança do modelo COM-Poisson,
definida como:

$$
\sum_i^n y_i \log(\lambda_i) - \nu \sum_i^n \log(y_i!) -
    \sum_i^n \log(Z(\lambda_i, \nu))
$$

em que $Z(\lambda_i, \nu) = \sum_{j=0}^\infty \lambda_i^j (j!)^{-\nu}$ e
$\lambda_i = \exp(X_i\beta)$

```{r}

llcmp

```

**Detalhes computacionais**

* Reparametrização do parâmetro $\nu$ para $\phi = \exp(\nu)$. Assim o
  espaçõ paramétrico do modelo são os reais $\Re^n$.

* Inclusão do termo _offset_. Somado diretamente ao preditor $X_i \beta$,
  pois $X_i \beta$ representa o parâmetro $\lambda$ de locação, da
  distribuição COM-Poisson.
  
* Truncamento da série infinita $Z(\lambda_i)$. `sumto` é tomado como
  argumento da função, que por padrão assume
  $\max(\underline{y})^{1.2}$.

* Para o cálculo de $Z(\lambda_i)$ faz-se, minimizando problemas de
  _overflow_
$$
\sum_{j=0}^\infty \lambda_i^j (j!)^{-\nu} = 
\sum_{j=0}^\infty \exp \left ( \log \left(
    \lambda_i^j (j!)^{-\nu} \right ) \right ) = 
\sum_{j=0}^\infty \exp(i \log(\lambda_i) - \nu \log(i!))
$$

## Ajuste geral ##

_Framework_ implementado em R que utiliza a forma de escrita de
preditores no estilo de fórmulas, similar as funções `lm`, `glm`. 

```{r}

cmp

```

Um exemplo de como são construídas as matrizes, definidos os chutes
iniciais e ajustados os modelos na função:

```{r}

set.seed(2016)
x <- rep(1:3, 2)
t <- rnorm(6, 5)
y <- rpois(6, lambda = x*t)
(da <- data.frame(x, t, y))

## Definindo o prditor do modelo
formula <- y ~ x + I(x^2) + offset(log(t))

##-------------------------------------------
## O framework

## Constrói as matrizes para ajuste do modelo
frame <- model.frame(formula, data = da)
(X <- model.matrix(formula, data = da))
(y <- model.response(frame))
(o <- model.offset(frame))

## Utiliza como valores iniciais as estimativas dos parametros de um
## modelo GLM-Poisson
m0 <- glm.fit(x = X, y = y, offset = o, family = poisson())
start <- c(phi = 0, m0$coefficients)

## Otimiza a função de log-verossimilhança via bbmle
library(bbmle)
parnames(llcmp) <- names(start)
mle2(llcmp, start = start,
     data = list(y = y, X = X, offset = o, sumto = 50),
     vecpar = TRUE)

```

# Capulhos de algodão sob efeito de desfolha #

```{r}

data(capdesfo)
str(capdesfo)
## help(capdesfo)

```

Experimento conduzido sob delineamento inteiramente casualizado em casa
de vegetação onde avaliou-se o número de capulhos produzidos por plantas
de algodão submetidas à níveis de desfolha artificial de remoção foliar
em combinação com o estágio fenológico no qual a desfolha foi aplicada.

* `est`: Estágio fenológico com cinco níveis (vegetativo, botão floral,
florecimento, maça, capulho);
* `des`: Nível de desfolha artificial de remoção foliar (0, 25, 50, 75,
  100\%);
* `ncap`: Número de capulhos de algodão produzidos ao final da ciclo
  cultura.

## Análise Exploratória ##

```{r}

## Experimento balanceado
xtabs(~est + des, data = capdesfo)

library(lattice)
library(latticeExtra)

(xy <- xyplot(ncap ~ des | est,
             data = capdesfo,
             xlab = "Nível de desfolha artificial",
             ylab = "Número de capulhos produzidos",
             type = c("p", "g", "smooth"),
             panel = panel.beeswarm,
             r = 0.05))

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(ncap ~ est + des, data = capdesfo,
                 FUN = function(x) c(mean = mean(x), var = var(x))))

xlim <- ylim <- extendrange(c(mv$ncap), f = 0.05)
xyplot(ncap[, "var"] ~ ncap[, "mean"],
       data = mv,
       xlim = xlim,
       ylim = ylim,
       ylab = "Variância Amostral",
       xlab = "Média Amostral",
       panel = function(x, y) {
           panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
           panel.abline(a = 0, b = 1, lty = 2)
       })

```

## Ajuste dos modelos ##

```{r}

## Preditores considerados
f1 <- ncap ~ 1
f2 <- ncap ~ des + I(des^2)
f3 <- ncap ~ est:des + I(des^2)
f4 <- ncap ~ est:(des + I(des^2))

## Ajustando os modelos Poisson
m1P <- glm(f1, data = capdesfo, family = poisson)
m2P <- glm(f2, data = capdesfo, family = poisson)
m3P <- glm(f3, data = capdesfo, family = poisson)
m4P <- glm(f4, data = capdesfo, family = poisson)

## Ajustando os modelos COM-Poisson
m1C <- cmp(f1, data = capdesfo)
m2C <- cmp(f2, data = capdesfo)
m3C <- cmp(f3, data = capdesfo)
m4C <- cmp(f4, data = capdesfo)

```

## Comparação dos ajustes ##

```{r}

## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(list(m1P, m2P, m3P, m4P), logLik),
      "COM-Poisson" = sapply(list(m1C, m2C, m3C, m4C), logLik))

## Teste de razão de verossimilhanças
anova(m1P, m2P, m3P, m4P, test = "Chisq")
anova(m1C, m2C, m3C, m4C)

```

```{r}

## Estimativas dos parâmetros
summary(m4P)
summary(m4C)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária
convergencez(m4C)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada
par(mfrow = c(2, 2))
plot(m4P)

```

```{r, cache = TRUE}

##-------------------------------------------
## Testando a nulidade do parâmetro phi

## Usando o ajuste Poisson
trv <- 2 * (logLik(m4C) - logLik(m4P))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m4Cfixed <- cmp(f4, data = capdesfo, fixed = list("phi" = 0))
anova(m4C, m4Cfixed)

## Via perfil de log-verossimilhança
perf <- profile(m4C, which = 1)
confint(perf)
plot(perf)

```

```{r}

##-------------------------------------------
## Verificando a matriz ve variâncias e covariâncias
Vcov <- vcov(m4C)
Corr <- cov2cor(Vcov)

library(corrplot)
corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r}

## Predição pontual
pred <- with(capdesfo,
             expand.grid(
                 est = levels(est),
                 des = seq(min(des), max(des), l = 20)
             ))

##-------------------------------------------
## Considerando a Poisson
mediasP <- exp(predict(m4P, newdata = pred))
aux <- data.frame(modelo = "Poisson", fit = mediasP)
predP <- cbind(pred, aux)

##-------------------------------------------
## Considerando a COM-Poisson
f4; f4[[2]] <- NULL; f4
X <- model.matrix(f4, data = pred)

## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m4C)[-1]
phi <- coef(m4C)[1]
loglambdas <- X %*% betas

## Aplicando a "inversa da função de ligação", ou seja, obtendo as
## contagens médias
mediasC <- sapply(loglambdas, FUN = function(p) {
    y <- 0:50; py <- dcmp(y, p, phi, sumto = 100)
    sum(y*py)
})
aux <- data.frame(modelo = "COM-Poisson", fit = mediasC)
predC <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos pelos dois modelos
da <- rbind(predP, predC)

update(xy, type = c("p", "g")) +
    as.layer(xyplot(fit ~ des | est,
                    groups = modelo,
                    data = da, type = "l"))

```

```{r}

## Predição intervalar
qn <- qnorm(0.975) * c(lwr = -1, upr = 1)

##-------------------------------------------
## Considerando a Poisson
aux <- predict(m4P, newdata = pred, se.fit = TRUE)
aux <- with(aux, exp(fit + outer(se.fit, qn, FUN = "*")))
predP <- cbind(predP, aux)

##-------------------------------------------
## Considerando a COM-Poisson

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov[-1, -1] - Vcov[-1, 1] %*% solve(Vcov[1, 1]) %*% Vcov[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:50; py <- dcmp(y, p, phi, sumto = 100)
                     sum(y*py)
                 })
             })
predC <- cbind(predC, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da <- rbind(predP, predC)

update(xy, type = c("p", "g")) +
    as.layer(xyplot(fit ~ des | est,
                    groups = modelo,
                    data = da,
                    type = "l",
                    ly = da$lwr,
                    uy = da$upr,
                    cty = "bands",
                    alpha = 0.3,
                    prepanel = prepanel.cbH,
                    panel.groups = panel.cbH,
                    panel = panel.superpose))

```

# Capulhos de algodão sob exposição à mosca-branca #

```{r}

data(capmosca)
str(capmosca)
## help(capmosca)

```

Experimento conduzido sob delineamento inteiramente casualizado na
Universidade Federal da Grande Dourados, cujo objetivo foi avaliar os
impactos da exposição de plantas de algodão à alta infestação da praga
mosca-branca. No experimento avaliou-se duas plantas por vaso, nesta
análise tomaremos como unidade amostral o vaso e o interesse será
somente na variável número de capulhos produzidos.

```{r}

capmosca <- aggregate(ncap ~ vaso + dexp, data = capmosca, FUN = sum)
str(capmosca)

```

Assim as variáveis consideradas são definidas como:

* `dexp`: Dias de exposição à alta infestação de mosca-branca;
* `ncap`: Número de capulhos de algodão produzidos ao final do
  experimento.

## Análise Exploratória ##

```{r}

## Experimento balanceado
xtabs(~dexp, data = capmosca)

(xy <- xyplot(ncap ~ dexp,
              data = capmosca,
              xlab = "Dias de infestação",
              ylab = "Número de capulhos produzidos",
              type = c("p", "g", "smooth"),
              panel = panel.beeswarm,
              r = 0.05))

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(ncap ~ dexp, data = capmosca,
                 FUN = function(x) c(mean = mean(x), var = var(x))))

```

## Ajuste dos modelos ##

```{r}

## Preditores considerados
f1 <- ncap ~ 1
f2 <- ncap ~ dexp
f3 <- ncap ~ dexp + I(dexp^2)

## Ajustando os modelos Poisson
m1P <- glm(f1, data = capmosca, family = poisson)
m2P <- glm(f2, data = capmosca, family = poisson)
m3P <- glm(f3, data = capmosca, family = poisson)

## Ajustando os modelos COM-Poisson
m1C <- cmp(f1, data = capmosca)
m2C <- cmp(f2, data = capmosca)
m3C <- cmp(f3, data = capmosca)

```

## Comparação dos ajustes ##

```{r}

## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(list(m1P, m2P, m3P), logLik),
      "COM-Poisson" = sapply(list(m1C, m2C, m3C), logLik))

## Teste de razão de verossimilhanças
anova(m1P, m2P, m3P, test = "Chisq")
anova(m1C, m2C, m3C)

```

```{r}

## Estimativas dos parâmetros
summary(m3P)
summary(m3C)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária
convergencez(m3C)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada
par(mfrow = c(2, 2))
plot(m3P)

```

```{r, cache = TRUE}

##-------------------------------------------
## Testando a nulidade do parâmetro phi

## Usando o ajuste Poisson
trv <- 2 * (logLik(m3C) - logLik(m3P))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m3Cfixed <- cmp(f3, data = capmosca, fixed = list("phi" = 0))
anova(m3C, m3Cfixed)

## Via perfil de log-verossimilhança
perf <- profile(m3C, which = 1)
confint(perf)
plot(perf)

```

```{r}

##-------------------------------------------
## Verificando a matriz ve variâncias e covariâncias
Vcov <- vcov(m3C)
Corr <- cov2cor(Vcov)

library(corrplot)
corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r}

## Predição pontual/intervalar
pred <- with(capmosca,
             expand.grid(
                 dexp = seq(min(dexp), max(dexp), l = 50)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

##-------------------------------------------
## Considerando a Poisson
aux <- predict(m3P, newdata = pred, se.fit = TRUE)
aux <- with(aux, exp(fit + outer(se.fit, qn, FUN = "*")))
aux <- data.frame(modelo = "Poisson", aux)
predP <- cbind(pred, aux)

##-------------------------------------------
## Considerando a COM-Poisson
f3; f3[[2]] <- NULL; f3
X <- model.matrix(f3, data = pred)

## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m3C)[-1]
phi <- coef(m3C)[1]
loglambdas <- X %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov[-1, -1] - Vcov[-1, 1] %*% solve(Vcov[1, 1]) %*% Vcov[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:30; py <- dcmp(y, p, phi, sumto = 50)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da <- rbind(predP, predC)

update(xy, type = c("p", "g")) +
    as.layer(xyplot(fit ~ dexp,
                    groups = modelo,
                    data = da,
                    type = "l",
                    ly = da$lwr,
                    uy = da$upr,
                    cty = "bands",
                    alpha = 0.3,
                    prepanel = prepanel.cbH,
                    panel.groups = panel.cbH,
                    panel = panel.superpose))

```

# Ocorrência de ninfas de mosca-branca em variedades de soja #

```{r}

data(ninfas)
str(ninfas)
## help(ninfas)

```

Experimento conduzido em casa de vegetação sob o delineamento de blocos
casualizados. No experimento foram avaliadas plantas de diferentes
cultivares de soja contabilizando o número de ninfas de mosca-branca nos
folíolos dos terços superior, médio e inferior das plantas. As
avaliações ocorreram em 6 datas dentre os 38 dias do estudo.

Nesta análise serão consideradas somente as cultivares com prefixo
\code{BRS}, sendo o número total de ninfas de mosca-branca nos folíolos
a variável de interesse.

```{r}

## Somente as cultivares que contém BRS na identificação
ninfas <- droplevels(subset(ninfas, grepl("BRS", x = cult)))

## Categorizando a variável dias em aval
ninfas$aval <- factor(ninfas$dias)

str(ninfas)

```

Assim as variáveis consideradas são definidas como:


## Análise Exploratória ##

```{r}

## Experimento balanceado
xtabs(~aval + cult, data = ninfas)

(xy <- xyplot(ntot ~ aval | cult,
              data = ninfas,
              type = c("p", "g", "smooth"),
              jitter.x = TRUE))

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(ntot ~ data + cult, data = ninfas,
                 FUN = function(x) c(mean = mean(x), var = var(x))))

xlim <- ylim <- extendrange(c(mv$ntot), f = 0.05)
xyplot(ntot[, "var"] ~ ntot[, "mean"],
       data = mv,
       xlim = xlim,
       ylim = ylim,
       ylab = "Variância Amostral",
       xlab = "Média Amostral",
       panel = function(x, y) {
           panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
           panel.abline(a = 0, b = 1, lty = 2)
       })

```

## Ajuste dos modelos ##

```{r, cache = TRUE}

## Preditores considerados
f1 <- ntot ~ bloco + cult + aval
f2 <- ntot ~ bloco + cult * aval

## Ajustando os modelos Poisson
m1P <- glm(f1, data = ninfas, family = poisson)
m2P <- glm(f2, data = ninfas, family = poisson)

## Ajustando os modelos COM-Poisson
m1C <- cmp(f1, data = ninfas, sumto = 600)
m2C <- cmp(f2, data = ninfas, sumto = 600)

```

## Comparação dos ajustes ##

```{r}

## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(list(m1P, m2P), logLik),
      "COM-Poisson" = sapply(list(m1C, m2C), logLik))

## Teste de razão de verossimilhanças
anova(m1P, m2P, test = "Chisq")
anova(m1C, m2C)

```

```{r}

## Estimativas dos parâmetros
summary(m1P)
summary(m1C)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária
convergencez(m1C, incremento = 100, maxit = 10)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada
par(mfrow = c(2, 2))
plot(m1P)

```

```{r, cache = TRUE}

##-------------------------------------------
## Testando a nulidade do parâmetro phi

## Usando o ajuste Poisson
trv <- 2 * (logLik(m1C) - logLik(m1P))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m1Cfixed <- cmp(f1, data = ninfas, fixed = list("phi" = 0))
anova(m1C, m1Cfixed)

## Via perfil de log-verossimilhança
perf <- profile(m1C, which = 1)
confint(perf)
plot(perf)

```

```{r}

##-------------------------------------------
## Verificando a matriz ve variâncias e covariâncias
Vcov <- vcov(m1C)
Corr <- cov2cor(Vcov)

library(corrplot)
corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r}

## Predição pontual/intervalar
pred <- with(ninfas,
             expand.grid(
                 bloco = factor(levels(bloco)[1],
                                levels = levels(bloco)),
                 cult = levels(cult),
                 aval = levels(aval)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

f1; f1[[2]] <- NULL; f1
X <- model.matrix(f1, data = pred)

## Como não temos interesse na interpretação dos efeitos de blocos
## tomaremos a média desses efeitos para predição

bl <- attr(X, "assign") == 1
X[, bl] <- X[, bl] * 0 + 1/(sum(bl) + 1)
head(X)

library(multcomp)

##-------------------------------------------
## Considerando a Poisson
aux <- exp(confint(glht(m1P, linfct = X),
               calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predP <- cbind(pred, aux)

##-------------------------------------------
## Considerando a COM-Poisson

## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m1C)[-1]
phi <- coef(m1C)[1]
loglambdas <- X %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov[-1, -1] - Vcov[-1, 1] %*% solve(Vcov[1, 1]) %*% Vcov[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:400; py <- dcmp(y, p, phi, sumto = 600)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da <- rbind(predP, predC)
da <- da[order(da$cult, da$aval, da$modelo), ]

source(paste0("https://gitlab.c3sl.ufpr.br/leg/legTools/raw/",
              "issue%2315/R/panel.segplot.by.R"))

update(xy, type = c("p", "g"), alpha = 0.5) +
    as.layer(segplot(
        aval ~ lwr + upr | cult, centers = fit,
        data = da, 
        horizontal = FALSE, draw = FALSE, lwd = 2, grid = TRUE,
        panel = panel.segplot.by, groups = modelo, f = 0.1,
        pch = 1:nlevels(pred$modelo)+2, as.table = TRUE))

```
