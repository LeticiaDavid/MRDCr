---
title: "Análise de Contagens com o Modelo COM-Poisson"
author: >
  Walmes M. Zeviani,
  Eduardo E. Ribeiro Jr &
  Cesar A. Taconeli
vignette: >
  %\VignetteIndexEntry{Análise de Contagens com o Modelo COM-Poisson}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
source("_setup.R")
```

```{r}

library(MRDCr)

```

# Funções para ajuste dos modelos #

## Log-verossimilhança ##

Implentando a função de log-verossimilhança do modelo COM-Poisson,
definida como:

$$
\sum_i^n y_i \log(\lambda_i) - \nu \sum_i^n \log(y_i!) -
    \sum_i^n \log(Z(\lambda_i, \nu))
$$

em que $Z(\lambda_i, \nu) = \sum_{j=0}^\infty \lambda_i^j (j!)^{-\nu}$ e
$\lambda_i = \exp(X_i\beta)$

```{r}

llcmp

```

**Detalhes computacionais**

* Reparametrização do parâmetro $\nu$ para $\phi = \exp(\nu)$. Assim o
  espaçõ paramétrico do modelo são os reais $\Re^n$.

* Inclusão do termo _offset_. Somado diretamente ao preditor $X_i \beta$,
  pois $X_i \beta$ representa o parâmetro $\lambda$ de locação, da
  distribuição COM-Poisson.
  
* Truncamento da série infinita $Z(\lambda_i)$. `sumto` é tomado como
  argumento da função, que por padrão assume
  $\max(\underline{y})^{1.2}$.

* Para o cálculo de $Z(\lambda_i)$ faz-se, minimizando problemas de
  _overflow_
$$
\sum_{j=0}^\infty \lambda_i^j (j!)^{-\nu} = 
\sum_{j=0}^\infty \exp \left ( \log \left(
    \lambda_i^j (j!)^{-\nu} \right ) \right ) = 
\sum_{j=0}^\infty \exp(i \log(\lambda_i) - \nu \log(i!))
$$

## Ajuste geral ##

_Framework_ implementado em R que utiliza a forma de escrita de
preditores no estilo de fórmulas, similar as funções `lm`, `glm`. 

```{r}

cmp

```

Um exemplo de como são construídas as matrizes, definidos os chutes
iniciais e ajustados os modelos na função:

```{r}

set.seed(2016)
x <- rep(1:3, 2)
t <- rnorm(6, 5)
y <- rpois(6, lambda = x*t)
(da <- data.frame(x, t, y))

## Definindo o prditor do modelo
formula <- y ~ x + I(x^2) + offset(log(t))

##-------------------------------------------
## O framework

## Constrói as matrizes para ajuste do modelo
frame <- model.frame(formula, data = da)
(X <- model.matrix(formula, data = da))
(y <- model.response(frame))
(o <- model.offset(frame))

## Utiliza como valores iniciais as estimativas dos parametros de um
## modelo GLM-Poisson
m0 <- glm.fit(x = X, y = y, offset = o, family = poisson())
start <- c(phi = 0, m0$coefficients)

## Otimiza a função de log-verossimilhança via bbmle
library(bbmle)
parnames(llcmp) <- names(start)
mle2(llcmp, start = start,
     data = list(y = y, X = X, offset = o, sumto = 50),
     vecpar = TRUE)

```

<!--==================================================================== -->
<!---->

# Capulhos de algodão sob exposição à mosca-branca #

```{r}

data(capmosca)
str(capmosca)
## help(capmosca)

```

Experimento conduzido sob delineamento inteiramente casualizado na
Universidade Federal da Grande Dourados, cujo objetivo foi avaliar os
impactos da exposição de plantas de algodão à alta infestação da praga
mosca-branca. No experimento avaliou-se duas plantas por vaso, nesta
análise tomaremos como unidade amostral o vaso e o interesse será
somente na variável número de capulhos produzidos.

```{r}

capmosca <- aggregate(ncap ~ vaso + dexp, data = capmosca, FUN = sum)
str(capmosca)

```

Assim as variáveis consideradas são definidas como:

* `dexp`: Dias de exposição à alta infestação de mosca-branca;
* `ncap`: Número de capulhos de algodão produzidos ao final do
  experimento.

## Análise Exploratória ##

```{r}

## Experimento balanceado
xtabs(~dexp, data = capmosca)

library(lattice)
library(latticeExtra)

(xy <- xyplot(ncap ~ dexp,
              data = capmosca,
              xlab = "Dias de infestação",
              ylab = "Número de capulhos produzidos",
              type = c("p", "g", "smooth"),
              panel = panel.beeswarm,
              r = 0.05))

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(ncap ~ dexp, data = capmosca,
                 FUN = function(x) c(mean = mean(x), var = var(x))))

```

## Ajuste dos modelos ##

```{r}

## Preditores considerados
f1 <- ncap ~ 1
f2 <- ncap ~ dexp
f3 <- ncap ~ dexp + I(dexp^2)

## Ajustando os modelos Poisson
m1P <- glm(f1, data = capmosca, family = poisson)
m2P <- glm(f2, data = capmosca, family = poisson)
m3P <- glm(f3, data = capmosca, family = poisson)

## Ajustando os modelos COM-Poisson
m1C <- cmp(f1, data = capmosca)
m2C <- cmp(f2, data = capmosca)
m3C <- cmp(f3, data = capmosca)

```

## Comparação dos ajustes ##

```{r}

library(bbmle)

## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(list(m1P, m2P, m3P), logLik),
      "COM-Poisson" = sapply(list(m1C, m2C, m3C), logLik))

## Teste de razão de verossimilhanças
anova(m1P, m2P, m3P, test = "Chisq")
anova(m1C, m2C, m3C)

```

```{r}

## Estimativas dos parâmetros
summary(m3P)
summary(m3C)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária
convergencez(m3C)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada
par(mfrow = c(2, 2))
plot(m3P)

```

```{r, cache = TRUE}

##-------------------------------------------
## Testando a nulidade do parâmetro phi

## Usando o ajuste Poisson
trv <- 2 * (logLik(m3C) - logLik(m3P))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m3Cfixed <- cmp(f3, data = capmosca, fixed = list("phi" = 0))
anova(m3C, m3Cfixed)

## Via perfil de log-verossimilhança
perf <- profile(m3C, which = 1)
confint(perf)
plot(perf)

```

```{r}

##-------------------------------------------
## Verificando a matriz ve variâncias e covariâncias
Vcov <- vcov(m3C)
Corr <- cov2cor(Vcov)

library(corrplot)
corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r}

## Predição pontual/intervalar
pred <- with(capmosca,
             expand.grid(
                 dexp = seq(min(dexp), max(dexp), l = 50)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

##-------------------------------------------
## Considerando a Poisson
aux <- predict(m3P, newdata = pred, se.fit = TRUE)
aux <- with(aux, exp(fit + outer(se.fit, qn, FUN = "*")))
aux <- data.frame(modelo = "Poisson", aux)
predP <- cbind(pred, aux)

##-------------------------------------------
## Considerando a COM-Poisson
f3; f3[-2]
X <- model.matrix(f3[-2], data = pred)

## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m3C)[-1]
phi <- coef(m3C)[1]
loglambdas <- X %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov[-1, -1] - Vcov[-1, 1] %*% solve(Vcov[1, 1]) %*% Vcov[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:30; py <- dcmp(y, p, phi, sumto = 50)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da <- rbind(predP, predC)

## Legenda
cols <- trellis.par.get("superpose.line")$col[1:2]
key <- list(
    lines = list(lty = 1, col = cols),
    rect = list(col = cols, alpha = 0.1, lty = 3, border = NA),
    text = list(c("Poisson", "COM-Poisson")))

## Gráfico dos valores preditos e IC de 95% para média 
update(xy, type = c("p", "g"), key = key, alpha = 0.7) +
    as.layer(xyplot(fit ~ dexp,
                    groups = modelo,
                    data = da,
                    type = "l",
                    ly = da$lwr,
                    uy = da$upr,
                    cty = "bands",
                    alpha = 0.5,
                    prepanel = prepanel.cbH,
                    panel.groups = panel.cbH,
                    panel = panel.superpose))

```


<!--==================================================================== -->
<!---->

# Produção de soja sob efeito de umidade e adubação potássica #

```{r}

data(soja)
str(soja)
## help(soja)

```

Dados resultantes de um experimento fatorial 5 $\times$ 3 conduzido em
casa de vegetação, onde experimentou-se diferentes níveis de umidade do
solo e níveis de adubação com potássio em parcelas que continham 2
plantas. O interesse deste estudo foi avaliar o impacto desses fatores
na produção de soja, mensurada pelos componentes número grãos e número
de vagegns viáveis. Para controle de variação local, as parcelas foram
arranjadas em blocos. Como temos somente três níveis de umidade
aplicados trabalharemos esta variável como categórica. Outra observação
é quanto a observação 74, que foi considerada como outlier pelo
pesquisador responsável e portanto retirada da análise.

```{r}

## Observação 74 foi diagnosticada como outlier
soja <- soja[-74, ]
soja <- transform(soja, K = factor(K))

```

Abaixo definimos as variáveis que são utilizadas na modelagem.

* `bloc`: Fator categórico para controle local no experimento. Foram
  controladas as variações de ambiente da casa de vegetação, como
  exposição ao sol, e mão de obra ao longo do experimento, como
  irrigação e capina dos vasos e controle de doenças.
* `umid`: Fator de níveis categóricos. Faixas de umidade do
  solo. Procurou-se por meio de pesagens diárias dos vasos, manter a
  umidade do solo nas faixas de 35 a 40; 47,5 a 52,5; e 60 a 65 do
  volume total de poros.
* `K`: fator de níveis métricos. Dose de potássio aplicado ao solo na
  forma de adubação, em mg dm$^{-3}$.

## Análise Exploratória ##

```{r, fig.height = 12}

## Experimento (des)balanceado
xtabs(~K + umid, data = soja)

key <- list(
    type = "b", divide = 1,
    ## points = list(pch = 1, col = cols),
    lines = list(pch = 1, lty = 1,
                 col = c(cols, trellis.par.get("dot.symbol")$col)),
    text = list(c("Nº de grãos por parcela", "Nº de vagens viáveis",
                  "Nº de grãos por vagem")))

xy1 <- xyplot(ngra + nvag ~ K | umid,
             data = soja,
             xlab = "Nível de adubação potássica",
             ylab = "Contagem",
             type = c("p", "g", "smooth"),
             key = key,
             layout = c(NA, 1),
             strip = strip.custom(
                 strip.names = TRUE, var.name = "Umidade"))

xy2 <- xyplot(ngra/nvag ~ K | umid,
             data = soja,
             xlab = "Nível de adubação potássica",
             ylab = "Contagem",
             type = c("p", "g", "smooth"),
             layout = c(NA, 1),
             strip = strip.custom(
                 strip.names = TRUE, var.name = "Umidade"))

print(xy1, split = c(1, 1, 1, 2), more = TRUE)
print(xy2, split = c(1, 2, 1, 2), more = FALSE)

```

```{r}

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(cbind(ngra, nvag, ng2v = ngra/nvag) ~ K + umid,
                 data = soja, FUN = function(x)
                     c(mean = mean(x), var = var(x))))

##-------------------------------------------
## Para o número de grãos
xlim <- ylim <- extendrange(c(mv$ngra), f = 0.05)
mvp1 <- xyplot(ngra[, "var"] ~ ngra[, "mean"],
               data = mv,
               xlim = xlim, ylim = ylim,
               ylab = "Variância Amostral",
               xlab = "Média Amostral",
               main = "Número de grãos por parcela",
               panel = function(x, y) {
                   panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
                   panel.abline(a = 0, b = 1, lty = 2)
               })

##-------------------------------------------
## Para o número de vagens
xlim <- ylim <- extendrange(c(mv$nvag), f = 0.05)
mvp2 <- xyplot(nvag[, "var"] ~ nvag[, "mean"],
               data = mv,
               xlim = xlim, ylim = ylim,
               ylab = "Variância Amostral",
               xlab = "Média Amostral",
               main = "Número de vagens viáveis",
               panel = function(x, y) {
                   panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
                   panel.abline(a = 0, b = 1, lty = 2)
               })

##-------------------------------------------
## Para o número de grãos por vagem
xlim <- ylim <- extendrange(c(mv$ng2v), f = 0.05)
mvp3 <- xyplot(ng2v[, "var"] ~ ng2v[, "mean"],
               data = mv,
               xlim = xlim, ylim = ylim,
               ylab = "Variância Amostral",
               xlab = "Média Amostral",
               main = "Número grãos por vagem",
               panel = function(x, y) {
                   panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
                   panel.abline(a = 0, b = 1, lty = 2)
               })

print(mvp1, split = c(1, 1, 3, 1), more = TRUE)
print(mvp2, split = c(2, 1, 3, 1), more = TRUE)
print(mvp3, split = c(3, 1, 3, 1), more = FALSE)

```

## Ajuste dos modelos ##

```{r}

##-------------------------------------------
## Para o número de vagens viáveis por parcela

## Preditores considerados
f1.nv <- nvag ~ bloc + umid + K
f2.nv <- nvag ~ bloc + umid * K

## Ajustando os modelos Poisson
m1P.nv <- glm(f1.nv, data = soja, family = poisson)
m2P.nv <- glm(f2.nv, data = soja, family = poisson)

## Ajustando os modelos COM-Poisson
m1C.nv <- cmp(f1.nv, data = soja, sumto = 300)
m2C.nv <- cmp(f2.nv, data = soja, sumto = 300)

##-------------------------------------------
## Para o número grão produzidos por parcela

## Preditores considerados
f1.ng <- ngra ~ bloc + umid + K
f2.ng <- ngra ~ bloc + umid * K

## Ajustando os modelos Poisson
m1P.ng <- glm(f1.ng, data = soja, family = poisson)
m2P.ng <- glm(f2.ng, data = soja, family = poisson)

## Ajustando os modelos COM-Poisson
m1C.ng <- cmp(f1.ng, data = soja, sumto = 700)
m2C.ng <- cmp(f2.ng, data = soja, sumto = 700)

##-------------------------------------------
## Para o número de grãos produzidos por vagem

## Preditores considerados
f1.gpv <- ngra ~ offset(log(nvag)) + bloc + umid + K
f2.gpv <- ngra ~ offset(log(nvag)) + bloc + umid * K

## Ajustando os modelos Poisson
m1P.gpv <- glm(f1.gpv, data = soja, family = poisson)
m2P.gpv <- glm(f2.gpv, data = soja, family = poisson)

## Ajustando os modelos COM-Poisson
m1C.gpv <- cmp(f1.gpv, data = soja, sumto = 350)
m2C.gpv <- cmp(f2.gpv, data = soja, sumto = 350)

```

## Comparação dos ajustes ##

```{r}

##-------------------------------------------
## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(
          list("nvagem adtv" = m1P.nv, "nvagem mult" = m2P.nv,
               "ngraos adtv" = m1P.ng, "ngraos mult" = m2P.ng,
               "ngrapv adtv" = m1P.gpv, "ngrapv mult" = m2P.gpv),
          logLik),
      "COM-Poisson" = sapply(
          list(m1C.nv, m2C.nv, m1C.ng, m2C.ng, m1C.gpv, m2C.gpv),
          logLik))

##-------------------------------------------
## Teste de razão de verossimilhanças

## Dos modelos para o número de vagens viáveis
anova(m1P.nv, m2P.nv, test = "Chisq")
anova(m1C.nv, m2C.nv)

## Dos modelos para o número de grão por parcela
anova(m1P.ng, m2P.ng, test = "Chisq")
anova(m1C.ng, m2C.ng)

## Dos modelos para o número de grão por vagem
anova(m1P.gpv, m2P.gpv, test = "Chisq")
anova(m1C.gpv, m2C.gpv)

```

```{r}
##-------------------------------------------
## Estimativas dos parâmetros do modelo proposto para

## o número de vagens viáveis
summary(m2P.nv)
summary(m2C.nv)

## o número de grão por parcela
summary(m2P.ng)
summary(m2C.ng)

## o número de grão por vagem
summary(m1P.gpv)
summary(m1C.gpv)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária

par(mfrow = c(1, 3))

## No modelo para o número de vagens viáveis
convergencez(m2C.nv)

## No modelo para o número de grão por parcela
convergencez(m2C.ng)

## No modelo para o número de grão por vagem
convergencez(m1C.gpv)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada

## Avaliação do modelo para o número de vagens viáveis
par(mfrow = c(2, 2))
plot(m2P.nv)

## Avaliação do modelo para o número de grão por parcela
par(mfrow = c(2, 2))
plot(m2P.ng)

## Avaliação do modelo para o número de grão por vagem
par(mfrow = c(2, 2))
plot(m1P.gpv)

```

```{r, cache = TRUE}

## Testando a nulidade do parâmetro phi

##-------------------------------------------
## No modelo para o número de vagens viáveis

## Usando o ajuste Poisson
trv <- 2 * (logLik(m2C.nv) - logLik(m2P.nv))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m2Cfixed.nv <- cmp(f2.nv, data = soja, fixed = list("phi" = 0),
                   sumto = 300)
anova(m2C.nv, m2Cfixed.nv)

##-------------------------------------------
## No modelo para o número de grão por parcela

## Usando o ajuste Poisson
trv <- 2 * (logLik(m2C.ng) - logLik(m2P.ng))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m2Cfixed.ng <- cmp(f2.ng, data = soja, fixed = list("phi" = 0),
                   sumto = 700)
anova(m2C.ng, m2Cfixed.ng)

##-------------------------------------------
## No modelo para o número de grão por vagem

## Usando o ajuste Poisson
trv <- 2 * (logLik(m1C.gpv) - logLik(m1P.gpv))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m1Cfixed.gpv <- cmp(f1.gpv, data = soja, fixed = list("phi" = 0),
                    sumto = 350)
anova(m1C.gpv, m1Cfixed.gpv)

##-------------------------------------------
## Via perfis de log-verossimilhança
perf.nv <- profile(m2C.nv, which = "phi")
perf.ng <- profile(m2C.ng, which = "phi")
perf.gpv <- profile(m1C.gpv, which = "phi")

par(mfrow = c(1, 3))
plot(perf.nv)
plot(perf.ng)
plot(perf.gpv)

confint(perf.nv)
confint(perf.ng)
confint(perf.gpv)

```

```{r}

## Verificando a matriz de variâncias e covariâncias

##-------------------------------------------
## No modelo para o número de vagens viáveis
Vcov.nv <- vcov(m2C.nv)
Corr <- cov2cor(Vcov.nv)

corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

##-------------------------------------------
## No modelo para o número de grão por parcela
Vcov.ng <- vcov(m2C.ng)
Corr <- cov2cor(Vcov.ng)

corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

## No modelo para o número de grão por vagem
Vcov.gpv <- vcov(m1C.gpv)
Corr <- cov2cor(Vcov.gpv)

corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r, fig.height = 18}

## Predição pontual/intervalar
pred <- with(soja,
             expand.grid(
                 bloc = factor(levels(bloc)[1], levels = levels(bloc)),
                 umid = levels(umid),
                 K = levels(K)
                 ## nvag = 1
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

## Definindos as matrizes de delineamento

## Do modelo com interação
f2.ng; f2.ng[-2]
X2 <- model.matrix(f2.ng[-2], data = pred)

## Como não temos interesse na interpretação dos efeitos de blocos
## tomaremos a média desses efeitos para predição
bl2 <- attr(X2, "assign") == 1
X2[, bl2] <- X2[, bl2] * 0 + 1/(sum(bl2) + 1)
head(X2)

## Do modelo aditivo, apenas retiramos os termos referentes ao efeito de
## interação
X1 <- X2[, attr(X2, "assign") != 4]
head(X1)

library(multcomp)

##-------------------------------------------
## Considerando a Poisson

## No modelo para o número de vagens
aux <- exp(confint(glht(m2P.nv, linfct = X2),
               calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predP.nv <- cbind(pred, aux)

## No modelo para o número de grãos por parcela
aux <- exp(confint(glht(m2P.ng, linfct = X2),
               calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predP.ng <- cbind(pred, aux)

## No modelo para o número de grãos por vagem
aux <- exp(confint(glht(m1P.gpv, linfct = X1),
               calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predP.gpv <- cbind(pred, aux)

##----------------------------------------------------------------------
## Considerando a COM-Poisson

##-------------------------------------------
## No modelo para o número de vagens
## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m2C.nv)[-1]
phi <- coef(m2C.nv)[1]
loglambdas <- X2 %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov.nv[-1, -1] - Vcov.nv[-1, 1] %*%
    solve(Vcov.nv[1, 1]) %*% Vcov.nv[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X2 %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:200; py <- dcmp(y, p, phi, sumto = 300)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC.nv <- cbind(pred, aux)

##-------------------------------------------
## No modelo para o número de grãos por parcela
## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m2C.ng)[-1]
phi <- coef(m2C.ng)[1]
loglambdas <- X2 %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov.ng[-1, -1] - Vcov.ng[-1, 1] %*%
    solve(Vcov.ng[1, 1]) %*% Vcov.ng[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X2 %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:350; py <- dcmp(y, p, phi, sumto = 700)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC.ng <- cbind(pred, aux)

##-------------------------------------------
## No modelo para o número de grãos por vagem
## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m1C.gpv)[-1]
phi <- coef(m1C.gpv)[1]
loglambdas <- X1 %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov.gpv[-1, -1] - Vcov.gpv[-1, 1] %*%
    solve(Vcov.gpv[1, 1]) %*% Vcov.gpv[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X1 %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:30; py <- dcmp(y, p, phi, sumto = 50)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC.gpv <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da.nv <- rbind(predP.nv, predC.nv)
da.nv <- da.nv[with(da.nv, order(umid, K, modelo)), ]

da.ng <- rbind(predP.ng, predC.ng)
da.ng <- da.ng[with(da.ng, order(umid, K, modelo)), ]

da.gpv <- rbind(predP.gpv, predC.gpv)
da.gpv <- da.gpv[with(da.gpv, order(umid, K, modelo)), ]

source(paste0("https://gitlab.c3sl.ufpr.br/leg/legTools/raw/",
              "issue%2315/R/panel.segplot.by.R"))

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(da.nv$modelo) + 3, lty = 1),
            text = list(c("Poisson", "COM-Poisson")))

xy1 <- xyplot(nvag ~ K | umid, data = soja,
       xlab = "Nível de adubação potássica",
       ylab = "Contagem",
       type = c("p", "g"), alpha = 0.7,
       key = key,
       layout = c(NA, 1),
       as.table = TRUE,
       strip = strip.custom(
           strip.names = TRUE, var.name = "Umidade")) +
    as.layer(    
        segplot(
            K ~ lwr + upr | umid,
            centers = fit, groups = modelo, data = da.nv,
            grid = TRUE, horizontal = FALSE, draw = FALSE,
            lwd = 2, pch = 1:nlevels(da$modelo) + 3,
            panel = panel.segplot.by, f = 0.1, as.table = TRUE)
    )    

xy2 <- xyplot(ngra ~ K | umid, data = soja,
       xlab = "Nível de adubação potássica",
       ylab = "Contagem",
       type = c("p", "g"), alpha = 0.7,
       ## key = key,
       layout = c(NA, 1),
       as.table = TRUE,
       strip = strip.custom(
           strip.names = TRUE, var.name = "Umidade")) +
    as.layer(    
        segplot(
            K ~ lwr + upr | umid,
            centers = fit, groups = modelo, data = da.ng,
            grid = TRUE, horizontal = FALSE, draw = FALSE,
            lwd = 2, pch = 1:nlevels(da$modelo) + 3,
            panel = panel.segplot.by, f = 0.1, as.table = TRUE)
    )    

xy3 <- xyplot(ngra/nvag ~ K | umid, data = soja,
       xlab = "Nível de adubação potássica",
       ylab = "Contagem",
       type = c("p", "g"), alpha = 0.7,
       ## key = key,
       layout = c(NA, 1),
       as.table = TRUE,
       strip = strip.custom(
           strip.names = TRUE, var.name = "Umidade")) +
    as.layer(    
        segplot(
            K ~ lwr + upr | umid,
            centers = fit, groups = modelo, data = da.gpv,
            grid = TRUE, horizontal = FALSE, draw = FALSE,
            lwd = 2, pch = 1:nlevels(da$modelo) + 3,
            panel = panel.segplot.by, f = 0.1, as.table = TRUE)
    )    

## x11(width = 10, height = 50)
print(xy1, split = c(1, 1, 1, 3), more = TRUE)
print(xy2, split = c(1, 2, 1, 3), more = TRUE)
print(xy3, split = c(1, 3, 1, 3), more = FALSE)

```

```{r, eval = FALSE}

## Testando o termo offset

##======================================================================
## offset 2 e lambda = 5
trat <- rep(letters[1:3], 30)
X <- model.matrix(~trat)
betas <- c(-0.5, -2, 1.5)
lambdas <- exp(X %*% betas)
y <- rpois(nrow(X), lambda = lambdas * 2)

kk <- data.frame(trat = trat, o = 2, y = y)
kkm <- cmp(y ~ offset(log(o)) + trat, data = kk, sumto = 50)
kkg <- glm(y ~ offset(log(o)) + trat, data = kk, family = poisson)

cbind(coef(kkm), c(NA, coef(kkg)))

##======================================================================

```

<!--==================================================================== -->
<!----> 

# Capulhos de algodão sob efeito de desfolha #

```{r}

data(capdesfo)
str(capdesfo)
## help(capdesfo)

```

Experimento conduzido sob delineamento inteiramente casualizado em casa
de vegetação onde avaliou-se o número de capulhos produzidos por plantas
de algodão submetidas à níveis de desfolha artificial de remoção foliar
em combinação com o estágio fenológico no qual a desfolha foi aplicada.

* `est`: Estágio fenológico com cinco níveis (vegetativo, botão floral,
florecimento, maça, capulho);
* `des`: Nível de desfolha artificial de remoção foliar (0, 25, 50, 75,
  100\%);
* `ncap`: Número de capulhos de algodão produzidos ao final da ciclo
  cultura.

## Análise Exploratória ##

```{r}

## Experimento balanceado
xtabs(~est + des, data = capdesfo)

(xy <- xyplot(ncap ~ des | est,
             data = capdesfo,
             xlab = "Nível de desfolha artificial",
             ylab = "Número de capulhos produzidos",
             type = c("p", "g", "smooth"),
             panel = panel.beeswarm,
             r = 0.05))

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(ncap ~ est + des, data = capdesfo,
                 FUN = function(x) c(mean = mean(x), var = var(x))))

xlim <- ylim <- extendrange(c(mv$ncap), f = 0.05)
xyplot(ncap[, "var"] ~ ncap[, "mean"],
       data = mv,
       xlim = xlim, ylim = ylim,
       ylab = "Variância Amostral",
       xlab = "Média Amostral",
       panel = function(x, y) {
           panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
           panel.abline(a = 0, b = 1, lty = 2)
       })

```

## Ajuste dos modelos ##

```{r}

## Preditores considerados
f1 <- ncap ~ 1
f2 <- ncap ~ des + I(des^2)
f3 <- ncap ~ est:des + I(des^2)
f4 <- ncap ~ est:(des + I(des^2))

## Ajustando os modelos Poisson
m1P <- glm(f1, data = capdesfo, family = poisson)
m2P <- glm(f2, data = capdesfo, family = poisson)
m3P <- glm(f3, data = capdesfo, family = poisson)
m4P <- glm(f4, data = capdesfo, family = poisson)

## Ajustando os modelos COM-Poisson
m1C <- cmp(f1, data = capdesfo)
m2C <- cmp(f2, data = capdesfo)
m3C <- cmp(f3, data = capdesfo)
m4C <- cmp(f4, data = capdesfo)

```

## Comparação dos ajustes ##

```{r}

## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(list(m1P, m2P, m3P, m4P), logLik),
      "COM-Poisson" = sapply(list(m1C, m2C, m3C, m4C), logLik))

## Teste de razão de verossimilhanças
anova(m1P, m2P, m3P, m4P, test = "Chisq")
anova(m1C, m2C, m3C, m4C)

```

```{r}

## Estimativas dos parâmetros
summary(m4P)
summary(m4C)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária
convergencez(m4C)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada
par(mfrow = c(2, 2))
plot(m4P)

```

```{r, cache = TRUE}

##-------------------------------------------
## Testando a nulidade do parâmetro phi

## Usando o ajuste Poisson
trv <- 2 * (logLik(m4C) - logLik(m4P))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m4Cfixed <- cmp(f4, data = capdesfo, fixed = list("phi" = 0))
anova(m4C, m4Cfixed)

## Via perfil de log-verossimilhança
perf <- profile(m4C, which = 1)
confint(perf)
plot(perf)

```

```{r}

##-------------------------------------------
## Verificando a matriz ve variâncias e covariâncias
Vcov <- vcov(m4C)
Corr <- cov2cor(Vcov)

library(corrplot)
corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r}

## Predição pontual/intervalar
pred <- with(capdesfo,
             expand.grid(
                 est = levels(est),
                 des = seq(min(des), max(des), l = 20)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

##-------------------------------------------
## Considerando a Poisson
aux <- predict(m4P, newdata = pred, se.fit = TRUE)
aux <- with(aux, exp(fit + outer(se.fit, qn, FUN = "*")))
aux <- data.frame(modelo = "Poisson", aux)
predP <- cbind(pred, aux)

##-------------------------------------------
## Considerando a COM-Poisson
f4; f4[-2]
X <- model.matrix(f4[-2], data = pred)

## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m4C)[-1]
phi <- coef(m4C)[1]
loglambdas <- X %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov[-1, -1] - Vcov[-1, 1] %*% solve(Vcov[1, 1]) %*% Vcov[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:50; py <- dcmp(y, p, phi, sumto = 100)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da <- rbind(predP, predC)

## Gráfico dos valores preditos e IC de 95% para média 
update(xy, type = c("p", "g"), key = key, alpha = 0.7) +
    as.layer(xyplot(fit ~ des | est,
                    groups = modelo,
                    data = da,
                    type = "l",
                    ly = da$lwr,
                    uy = da$upr,
                    cty = "bands",
                    alpha = 0.5,
                    prepanel = prepanel.cbH,
                    panel.groups = panel.cbH,
                    panel = panel.superpose))

```

<!--==================================================================== -->
<!---->

# Ocorrência de ninfas de mosca-branca em variedades de soja #

```{r}

data(ninfas)
str(ninfas)
## help(ninfas)

```

Experimento conduzido em casa de vegetação sob o delineamento de blocos
casualizados. No experimento foram avaliadas plantas de diferentes
cultivares de soja contabilizando o número de ninfas de mosca-branca nos
folíolos dos terços superior, médio e inferior das plantas. As
avaliações ocorreram em 6 datas dentre os 38 dias do estudo.

Nesta análise serão consideradas somente as cultivares com prefixo
\code{BRS}, sendo o número total de ninfas de mosca-branca nos folíolos
a variável de interesse.

```{r}

## Somente as cultivares que contém BRS na identificação
ninfas <- droplevels(subset(ninfas, grepl("BRS", x = cult)))

## Categorizando a variável dias em aval
ninfas$aval <- factor(ninfas$dias)

str(ninfas)

```

Assim as variáveis consideradas são definidas como:

* `bloco`: Fator com 4 níveis que representam os blocos utilizados para
  controle de variação local.
* `cult`: Fator com a identificação da cultivar de soja. Foram 4
  cultivares (com prefixo BRS).
* `aval`: Fator que indica o número de dias, após o início do
  experimento em que realizou-se as avaliações. Houve avaliações em 6
  datas.

## Análise Exploratória ##

```{r}

## Experimento balanceado
xtabs(~aval + cult, data = ninfas)

(xy <- xyplot(ntot ~ aval | cult,
              data = ninfas,
              type = c("p", "g", "smooth"),
              jitter.x = TRUE))

## Avaliando preliminarmente suposição de equidispersão
(mv <- aggregate(ntot ~ data + cult, data = ninfas,
                 FUN = function(x) c(mean = mean(x), var = var(x))))

xlim <- ylim <- extendrange(c(mv$ntot), f = 0.05)
xyplot(ntot[, "var"] ~ ntot[, "mean"],
       data = mv,
       ## xlim = xlim,  ylim = ylim,
       ylab = "Variância Amostral",
       xlab = "Média Amostral",
       panel = function(x, y) {
           panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
           panel.abline(a = 0, b = 1, lty = 2)
       })

```

## Ajuste dos modelos ##

```{r, cache = TRUE}

## Preditores considerados
f1 <- ntot ~ bloco + cult + aval
f2 <- ntot ~ bloco + cult * aval

## Ajustando os modelos Poisson
m1P <- glm(f1, data = ninfas, family = poisson)
m2P <- glm(f2, data = ninfas, family = poisson)

## Ajustando os modelos COM-Poisson
m1C <- cmp(f1, data = ninfas, sumto = 600)
m2C <- cmp(f2, data = ninfas, sumto = 600)

```

## Comparação dos ajustes ##

```{r}

## Verossimilhancas dos modelos ajustados
cbind("Poisson" = sapply(list(m1P, m2P), logLik),
      "COM-Poisson" = sapply(list(m1C, m2C), logLik))

## Teste de razão de verossimilhanças
anova(m1P, m2P, test = "Chisq")
anova(m1C, m2C)

```

```{r}

## Estimativas dos parâmetros
summary(m1P)
summary(m1C)

```

## Avaliando modelo proposto ##

```{r}

## Um dos problemas computacionais do modelo COM-Poisson é a obtenção da
## constante de normalização Z. Assim uma visualização pós ajuste para
## verificar se o ajuste proporcionou uma densidade válida se faz
## necessária
convergencez(m1C, incremento = 100, maxit = 10)

```

```{r}

## Dado que o modelo COM-Poisson leva as mesmas estimativas pontuais que
## o modelo Poisson a análise de diagnóstico padrão pode ser utilizada
par(mfrow = c(2, 2))
plot(m1P)

```

```{r, cache = TRUE}

##-------------------------------------------
## Testando a nulidade do parâmetro phi

## Usando o ajuste Poisson
trv <- 2 * (logLik(m1C) - logLik(m1P))
attributes(trv) <- NULL
round(c(trv, pchisq(trv, 1, lower = FALSE)), digits = 5)

## Reajustando o COM-Poisson para phi = 0 (ou equivalente nu = 1)
m1Cfixed <- cmp(f1, data = ninfas, fixed = list("phi" = 0))
anova(m1C, m1Cfixed)

## Via perfil de log-verossimilhança
perf <- profile(m1C, which = 1)
confint(perf)
plot(perf)

```

```{r}

##-------------------------------------------
## Verificando a matriz ve variâncias e covariâncias
Vcov <- vcov(m1C)
Corr <- cov2cor(Vcov)

library(corrplot)
corrplot.mixed(Corr, lower = "number", upper = "ellipse",
               diag = "l", tl.pos = "lt", tl.col = "black",
               tl.cex = 0.8, col = brewer.pal(9, "Greys")[-(1:3)])

```

## Predição ##

```{r}

## Predição pontual/intervalar
pred <- with(ninfas,
             expand.grid(
                 bloco = factor(levels(bloco)[1],
                                levels = levels(bloco)),
                 cult = levels(cult),
                 aval = levels(aval)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

f1; f1[-2]
X <- model.matrix(f1[-2], data = pred)

## Como não temos interesse na interpretação dos efeitos de blocos
## tomaremos a média desses efeitos para predição

bl <- attr(X, "assign") == 1
X[, bl] <- X[, bl] * 0 + 1/(sum(bl) + 1)
head(X)

library(multcomp)

##-------------------------------------------
## Considerando a Poisson
aux <- exp(confint(glht(m1P, linfct = X),
               calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predP <- cbind(pred, aux)

##-------------------------------------------
## Considerando a COM-Poisson

## Obtendo os parâmetros da distribuição (lambdas e phi)
betas <- coef(m1C)[-1]
phi <- coef(m1C)[1]
loglambdas <- X %*% betas

## Obtendo os erros padrão das estimativas
##   Obs.: Deve-se usar a matriz de variâncias e covariâncias
##   condicional, pois os parâmetros de locação (betas) e dispersão
##   (phi) não são ortogonais.
Vc <- Vcov[-1, -1] - Vcov[-1, 1] %*% solve(Vcov[1, 1]) %*% Vcov[1, -1]
U <- chol(Vc)
se <- sqrt(apply(X %*% t(U), MARGIN = 1, FUN = function(x) {
    sum(x^2)
}))

aux <- c(loglambdas) + outer(se, qn, FUN = "*")
aux <- apply(aux, MARGIN = 2,
             FUN = function(col) {
                 sapply(col, FUN = function(p) {
                     y <- 0:400; py <- dcmp(y, p, phi, sumto = 600)
                     sum(y*py)
                 })
             })
aux <- data.frame(modelo = "COM-Poisson", aux)
predC <- cbind(pred, aux)

##-------------------------------------------
## Visualizando os valores preditos intervalares pelos dois modelos
da <- rbind(predP, predC)
da <- da[order(da$cult, da$aval, da$modelo), ]

source(paste0("https://gitlab.c3sl.ufpr.br/leg/legTools/raw/",
              "issue%2315/R/panel.segplot.by.R"))

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(da$modelo) + 3, lty = 1),
            text = list(c("Poisson", "COM-Poisson")))

update(xy, type = c("p", "g"), key = key, alpha = 0.7) +
    as.layer(segplot(
        aval ~ lwr + upr | cult,
        centers = fit, groups = modelo, data = da,
        grid = TRUE, horizontal = FALSE, draw = FALSE,
        lwd = 2, pch = 1:nlevels(da$modelo) + 3,
        panel = panel.segplot.by, f = 0.1))

```
